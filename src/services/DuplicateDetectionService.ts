import { AnalysisResult, DuplicateGroup, Photo } from '../types';
import { databaseService } from './DatabaseService';
import { photoService } from './PhotoService';
import { perceptualHashService } from './PerceptualHashService';

export class DuplicateDetectionService {
  
  // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ - å‡¦ç†é–‹å§‹æ™‚ã«ä¸€åº¦ã ã‘å…¨å†™çœŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
  private photoMetadataCache: Map<string, any> = new Map();
  
  /**
   * Initialize metadata cache to avoid repeated database queries
   */
  private async initializeMetadataCache(): Promise<void> {
    try {
      console.log('ğŸ”¬ Initializing photo metadata cache...');
      const allPhotos = await databaseService.getAllPhotos();
      this.photoMetadataCache.clear();
      
      for (const photo of allPhotos) {
        this.photoMetadataCache.set(photo.localIdentifier, photo);
      }
      
      console.log(`ğŸ”¬ Metadata cache initialized with ${this.photoMetadataCache.size} photos`);
    } catch (error) {
      console.error('ğŸ”¬ âŒ Failed to initialize metadata cache:', error);
      throw error;
    }
  }
  
  /**
   * Get the stored hash for a photo from cache (no database query)
   */
  private getPhotoHashFromCache(photo: Photo): string | null {
    const metadata = this.photoMetadataCache.get(photo.localIdentifier);
    if (!metadata) {
      console.warn(`ğŸ”¬ âš ï¸ Photo metadata not found in cache for: ${photo.filename} (${photo.localIdentifier})`);
      console.warn('ğŸ”¬ âš ï¸ This photo will be excluded from duplicate comparison');
      return null;
    }
    
    if (!metadata.hashValue) {
      console.warn(`ğŸ”¬ âš ï¸ Hash value missing for photo: ${photo.filename} (${photo.localIdentifier})`);
      console.warn('ğŸ”¬ âš ï¸ This photo will be excluded from duplicate comparison');
      return null;
    }
    
    return metadata.hashValue;
  }
  
  /**
   * Clear all existing duplicate groups for fresh analysis
   */
  private async clearAllDuplicateGroups(): Promise<void> {
    try {
      await databaseService.clearAllDuplicateGroups();
      console.log('ğŸ”¬ âœ… Cleared all existing duplicate groups');
    } catch (error) {
      console.error('ğŸ”¬ âŒ Failed to clear duplicate groups:', error);
      throw error;
    }
  }
  
  async analyzePhotos(
    photos: Photo[], 
    onProgress?: (progress: number, message: string) => void,
    clearExistingGroups: boolean = false
  ): Promise<AnalysisResult> {
    console.log('ğŸ”¬ analyzePhotos started with', photos.length, 'photos');
    const startTime = Date.now();
    let analyzedCount = 0;
    
    try {
      // Clear existing duplicate groups if requested
      if (clearExistingGroups) {
        console.log('ğŸ”¬ Clearing existing duplicate groups...');
        await this.clearAllDuplicateGroups();
        onProgress?.(5, 'æ—¢å­˜ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ã‚¯ãƒªã‚¢ä¸­...');
      }
      
      // Create analysis session
      console.log('ğŸ”¬ Creating analysis session...');
      const sessionUuid = await databaseService.createAnalysisSession(photos.length);
      console.log('ğŸ”¬ Analysis session created:', sessionUuid);
    
      onProgress?.(0, 'å†™çœŸã‚’æº–å‚™ä¸­...');
      
      // Save photos to database and calculate hashes
      console.log('ğŸ”¬ Initializing data structures...');
      const photoMap = new Map<string, Photo>();
      const hashMap = new Map<string, Photo[]>();
      console.log('ğŸ”¬ Data structures initialized');
      
      for (let i = 0; i < photos.length; i++) {
        const photo = photos[i];
        try {
          console.log(`ğŸ”¬ Processing photo ${i + 1}/${photos.length}: ${photo.filename}`);
          
          // Calculate visual-only hash for duplicate detection  
          console.log('ğŸ”¬ Calculating visual-only hash for:', photo.filename);
          console.log(`ğŸ”¬ Photo details: ${photo.width}x${photo.height}, ${photo.fileSize} bytes, URI: ${photo.uri.substring(0, 50)}...`);
          
          const hash = await perceptualHashService.calculateVisualHash(photo);
          console.log('ğŸ”¬ Visual hash calculated:', hash.substring(0, 8) + '...');
          console.log(`ğŸ”¬ Full hash: ${hash}`);
          
          // Ensure hash is always exactly 64 characters before any processing
          const finalHash = perceptualHashService.normalizeHashLength(hash);
          console.log(`ğŸ”¬ === HASH PROCESSING ===`);
          console.log(`ğŸ”¬ Original hash: ${hash}`);
          console.log(`ğŸ”¬ Final hash: ${finalHash}`);
          console.log(`ğŸ”¬ Hash length: ${finalHash.length} characters`);
          console.log(`ğŸ”¬ ========================`);
          
          // Save photo metadata to database with normalized hash
          console.log('ğŸ”¬ Converting to photo metadata...');
          const photoMetadata = photoService.convertToPhotoMetadata(photo);
          photoMetadata.hashValue = finalHash;
          
          console.log(`ğŸ”¬ Saving photo with hash: ${finalHash.substring(0, 16)}...`);
          await databaseService.savePhoto(photoMetadata);
          console.log('ğŸ”¬ âœ… Photo saved to database successfully');
          
          if (!hashMap.has(finalHash)) {
            hashMap.set(finalHash, []);
          }
          hashMap.get(finalHash)!.push(photo);
          photoMap.set(photo.id, photo);
          
          analyzedCount++;
          const progress = (analyzedCount / photos.length) * 100;
          onProgress?.(progress, `åˆ†æä¸­: ${analyzedCount}/${photos.length}æš`);
          
        } catch (error) {
          console.error('ğŸ”¬ âŒ Failed to process photo:', photo.filename);
          console.error('ğŸ”¬ âŒ Error details:', error);
          console.error('ğŸ”¬ âŒ Error stack:', error instanceof Error ? error.stack : 'No stack');
          // Continue with next photo
        }
      }
      
      onProgress?.(90, 'é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆä¸­...');
      
      // Initialize metadata cache before duplicate detection
      console.log('ğŸ”¬ Initializing metadata cache for performance optimization...');
      await this.initializeMetadataCache();
      
      // Enhanced duplicate detection using Hamming distance for visual similarity
      console.log('ğŸ”¬ Starting visual duplicate detection with Hamming distance...');
      const duplicateGroups: DuplicateGroup[] = [];
      let totalDuplicates = 0;
      let totalSpaceSaved = 0;
      
      // Group photos by similarity using Hamming distance
      const allPhotos = Array.from(photoMap.values());
      const processedPhotos = new Set<string>();
      const confirmedDuplicates: Photo[][] = [];
      
      // Filter photos that have valid hashes in cache
      const photosWithHashes = allPhotos.filter(photo => {
        const hash = this.getPhotoHashFromCache(photo);
        return hash !== null;
      });
      
      console.log(`ğŸ”¬ Processing ${photosWithHashes.length}/${allPhotos.length} photos with valid hashes`);
      
      for (let i = 0; i < photosWithHashes.length; i++) {
        if (processedPhotos.has(photosWithHashes[i].id)) continue;
        
        const currentPhoto = photosWithHashes[i];
        const currentHash = this.getPhotoHashFromCache(currentPhoto);
        if (!currentHash) continue; // Should not happen due to filtering above
        
        const similarGroup: Photo[] = [currentPhoto];
        processedPhotos.add(currentPhoto.id);
        
        // Find all photos similar to current photo using Hamming distance
        for (let j = i + 1; j < photosWithHashes.length; j++) {
          if (processedPhotos.has(photosWithHashes[j].id)) continue;
          
          const comparePhoto = photosWithHashes[j];
          const compareHash = this.getPhotoHashFromCache(comparePhoto);
          if (!compareHash) continue; // Should not happen due to filtering above
          
          // Use perceptual hash service to check visual similarity with relaxed threshold
          if (perceptualHashService.isVisuallySimilar(currentHash, compareHash, 15)) {
            similarGroup.push(comparePhoto);
            processedPhotos.add(comparePhoto.id);
            console.log(`ğŸ”¬ Found visually similar photo: ${comparePhoto.filename} (Hamming distance â‰¤15)`);
          }
        }
        
        // Only create group if we found duplicates
        if (similarGroup.length > 1) {
          confirmedDuplicates.push(similarGroup);
          console.log(`ğŸ”¬ Created duplicate group with ${similarGroup.length} visually similar photos`);
        }
      }
          
      // Create duplicate groups for confirmed duplicates
      for (const duplicateSet of confirmedDuplicates) {
        try {
          // Get photo metadata from cache (no database queries)
          const photoMetadataList = [];
          for (const photo of duplicateSet) {
            const metadata = this.photoMetadataCache.get(photo.localIdentifier);
            if (metadata) {
              photoMetadataList.push(metadata);
            } else {
              console.warn(`ğŸ”¬ âš ï¸ Metadata not found in cache for duplicate group photo: ${photo.filename}`);
            }
          }
          
          if (photoMetadataList.length > 1) {
            // Create a representative group hash from all similar photos
            // Sort hashes to ensure consistent group identification
            const allHashes = photoMetadataList
              .map(p => p.hashValue)
              .filter(h => h)
              .sort();
            
            // Use the most common hash pattern or first hash as group representative
            const groupHash = allHashes[0] || 'unknown';
            
            console.log(`ğŸ“Š Creating group with ${photoMetadataList.length} photos`);
            console.log(`ğŸ“Š Representative hash: ${groupHash.substring(0, 16)}...`);
            console.log(`ğŸ“Š All hashes: ${allHashes.map(h => h?.substring(0, 8)).join(', ')}`);
            
            // Create duplicate group in database
            const photoIds = photoMetadataList.map(p => typeof p.id === 'string' ? parseInt(p.id) : p.id);
            const groupId = await databaseService.createDuplicateGroup(groupHash, photoIds);
            
            // Calculate space that could be saved (all but one photo)
            const totalSize = duplicateSet.reduce((sum, p) => sum + p.fileSize, 0);
            const largestPhoto = duplicateSet.reduce((largest, current) => 
              current.fileSize > largest.fileSize ? current : largest
            );
            const spaceSaved = totalSize - largestPhoto.fileSize;
            
            duplicateGroups.push({
              id: groupId.toString(),
              groupHash: groupHash,
              photoCount: duplicateSet.length,
              totalSize: totalSize,
              photos: photoMetadataList,
              recommendedKeepId: photoMetadataList.find(p => p.localIdentifier === largestPhoto.localIdentifier)?.id || photoMetadataList[0].id
            });
            
            totalDuplicates += duplicateSet.length - 1; // Count duplicates to remove
            totalSpaceSaved += spaceSaved;
            
            console.log(`ğŸ”¬ âœ… Created duplicate group: ${duplicateSet.length} photos, ${(spaceSaved / 1024 / 1024).toFixed(1)}MB savings`);
          }
        } catch (error) {
          console.error('ğŸ”¬ âŒ Failed to create duplicate group:', error);
        }
      }
      
      const processingTime = Date.now() - startTime;
      
      // Update analysis session
      await databaseService.updateAnalysisSession(sessionUuid, {
        analyzedPhotos: analyzedCount,
        duplicatesFound: totalDuplicates,
        totalSizeAnalyzed: photos.reduce((sum, p) => sum + p.fileSize, 0),
        potentialSpaceSaved: totalSpaceSaved,
        endTime: new Date().toISOString(),
        status: 'completed'
      });
      
      onProgress?.(100, 'åˆ†æå®Œäº†ï¼');
      
      return {
        totalPhotos: photos.length,
        duplicatesFound: totalDuplicates,
        duplicateGroups,
        potentialSpaceSaved: totalSpaceSaved,
        processingTime
      };
      
    } catch (error) {
      console.error('ğŸ”¬ âŒ Analysis failed at top level:', error);
      console.error('ğŸ”¬ âŒ Error type:', typeof error);
      console.error('ğŸ”¬ âŒ Error message:', error instanceof Error ? error.message : String(error));
      console.error('ğŸ”¬ âŒ Error stack:', error instanceof Error ? error.stack : 'No stack');
      
      try {
        // Update session with error
        console.log('ğŸ”¬ Updating session with error...');
        const sessionUuid = 'error-session'; // Fallback if sessionUuid is not available
        await databaseService.updateAnalysisSession(sessionUuid, {
          status: 'error',
          errorMessage: error instanceof Error ? error.message : 'Unknown error',
          endTime: new Date().toISOString()
        });
      } catch (updateError) {
        console.error('ğŸ”¬ âŒ Failed to update session with error:', updateError);
      }
      
      throw error;
    }
  }
  
  
  async deleteDuplicatePhotos(_groupId: string, photoIdsToDelete: string[]): Promise<{
    success: boolean;
    deletedCount: number;
    errors: string[];
  }> {
    const errors: string[] = [];
    let deletedCount = 0;
    
    try {
      console.log('ğŸ—‘ï¸ Starting deletion process...');
      console.log('ğŸ—‘ï¸ Photo IDs to delete:', photoIdsToDelete);
      
      // Get photo metadata including localIdentifier for actual deletion
      const photosToDelete = [];
      for (const photoId of photoIdsToDelete) {
        try {
          const id = typeof photoId === 'string' ? parseInt(photoId) : photoId;
          const photo = await databaseService.getPhoto(id);
          if (photo) {
            photosToDelete.push(photo);
            console.log(`ğŸ—‘ï¸ Found photo to delete: ${photo.fileName} (${photo.localIdentifier})`);
          } else {
            console.warn(`ğŸ—‘ï¸ âš ï¸ Photo not found in database: ID ${photoId}`);
            errors.push(`Photo not found: ${photoId}`);
          }
        } catch (error) {
          console.error(`ğŸ—‘ï¸ âŒ Failed to get photo metadata for ID ${photoId}:`, error);
          errors.push(`Failed to get photo metadata: ${photoId}`);
        }
      }
      
      if (photosToDelete.length === 0) {
        console.warn('ğŸ—‘ï¸ âš ï¸ No photos found to delete');
        return {
          success: false,
          deletedCount: 0,
          errors: ['No photos found to delete']
        };
      }
      
      // Delete from device using localIdentifiers
      console.log('ğŸ—‘ï¸ Deleting from device...');
      const localIdentifiers = photosToDelete.map(photo => photo.localIdentifier);
      const deleteResult = await photoService.deletePhotos(localIdentifiers);
      deletedCount = deleteResult.deletedCount;
      console.log(`ğŸ—‘ï¸ Device deletion result: ${deletedCount}/${localIdentifiers.length} deleted`);
      
      // Mark as deleted in database
      console.log('ğŸ—‘ï¸ Updating database...');
      for (const photo of photosToDelete) {
        try {
          const id = typeof photo.id === 'string' ? parseInt(photo.id) : photo.id;
          await databaseService.updatePhoto(id, { isDeleted: true });
          console.log(`ğŸ—‘ï¸ âœ… Marked as deleted in DB: ${photo.fileName}`);
        } catch (error) {
          console.error(`ğŸ—‘ï¸ âŒ Failed to update database for photo ${photo.fileName}:`, error);
          errors.push(`Failed to update database for photo ${photo.fileName}`);
        }
      }
      
      const success = deletedCount > 0;
      console.log(`ğŸ—‘ï¸ Deletion complete: success=${success}, deleted=${deletedCount}, errors=${errors.length}`);
      
      return {
        success,
        deletedCount,
        errors
      };
      
    } catch (error) {
      console.error('ğŸ—‘ï¸ âŒ Deletion process failed:', error);
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      errors.push(errorMessage);
      return {
        success: false,
        deletedCount: 0,
        errors
      };
    }
  }
  
  /**
   * Update analysis session statistics after deletion
   */
  async updateSessionAfterDeletion(deletedCount: number, spaceSaved: number): Promise<void> {
    try {
      console.log('ğŸ“Š Updating session statistics after deletion...');
      console.log(`ğŸ“Š Deleted photos: ${deletedCount}, Space saved: ${spaceSaved} bytes`);
      
      const latestSession = await databaseService.getLatestAnalysisSession();
      if (!latestSession) {
        console.warn('ğŸ“Š âš ï¸ No analysis session found to update');
        return;
      }
      
      // Calculate actual space saved
      const spaceMB = (spaceSaved / (1024 * 1024)).toFixed(1);
      console.log(`ğŸ“Š Space saved: ${spaceMB}MB`);
      
      // Update session with actual deletion results
      await databaseService.updateAnalysisSession(latestSession.sessionUuid, {
        potentialSpaceSaved: spaceSaved,
        duplicatesFound: deletedCount,
        endTime: new Date().toISOString(),
        status: 'completed'
      });
      
      console.log('ğŸ“Š âœ… Session statistics updated successfully');
    } catch (error) {
      console.error('ğŸ“Š âŒ Failed to update session statistics:', error);
    }
  }
  
  formatAnalysisResult(result: AnalysisResult): string {
    const { totalPhotos, duplicatesFound, potentialSpaceSaved, processingTime } = result;
    
    const spaceMB = (potentialSpaceSaved / (1024 * 1024)).toFixed(1);
    const timeSeconds = (processingTime / 1000).toFixed(1);
    
    return `åˆ†æå®Œäº†: ${totalPhotos}æšä¸­${duplicatesFound}æšã®é‡è¤‡ã‚’ç™ºè¦‹ã€‚` +
           `${spaceMB}MBã®å®¹é‡å‰Šæ¸›ãŒå¯èƒ½ã§ã™ã€‚å‡¦ç†æ™‚é–“: ${timeSeconds}ç§’`;
  }
}

export const duplicateDetectionService = new DuplicateDetectionService();